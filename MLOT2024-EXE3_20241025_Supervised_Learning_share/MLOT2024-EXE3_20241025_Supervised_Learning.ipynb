{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dcc6c619-c02a-4bea-b322-4f32779ae672",
    "_uuid": "819c6b57207e720308ea29491d85a6e8af8c253e"
   },
   "source": [
    "# Supervised Learning\n",
    "\n",
    "We will not focus on understanding the math behind the machine learning techniques. We will focus on understanding basics of machine learning and learning how to implement it while using **python**.\n",
    "\n",
    "In python there are different ML libraries, including sklearn, keras or tensorflow. In this exercise we will use **sklearn**.\n",
    "\n",
    "Supervised learning uses data that has labels. Example, there are orthopedic patients data that have labels *normal* and *abnormal*.\n",
    "* **Variables**: There are features (predictor variable) and target variable\n",
    "    * Features in our example include *pelvic radius* or *sacral slope*\n",
    "    * Target variables are labels, *normal* and *abnormal* in our example\n",
    "* **Goal** is that based on given features (input) predict whether target variable (output) is *normal* or *abnormal*\n",
    "* **Classification**: target variable consists of categories, e.g. normal or abnormal\n",
    "* **Regression**: target variable is continious, e.g. stock market\n",
    "\n",
    "* **Note**:\n",
    "    * feature = variable = predictor variable = independent variable = column = input \n",
    "    * target variable = response variable = class = dependent variable = output = result   \n",
    "\n",
    "  Contents of this excercise:\n",
    "\n",
    "     1. [EDA (Exploratory Data Analysis)](#1)\n",
    "     1. [CLASSIFIATION: K-Nearest Neighbors (KNN)](#2)\n",
    "         1. [KNN](#3)\n",
    "         1. [Accuracy](#4)\n",
    "         1. [Split train and test data](#5)\n",
    "         1. [Model optimisatation](#6)\n",
    "         1. [Confusion matrix](#7)\n",
    "         1. [TODO No. 1: Random Forest (OPTIONAL)](#8)\n",
    "     1. [REGRESSION](#9)\n",
    "         1. [Linear regression](#10)\n",
    "         1. [Regularised regression](#11)\n",
    "         1. [TODO No. 2: Regression (OPTIONAL)](#12)\n",
    "     1. [Logistic Regression and ROC Curve](#13)\n",
    "     1. [Cross validation](#14)\n",
    "     1. [Hyperparameter tunning](#15)\n",
    "         1. [TODO No. 3:  Grid search example with 2 hyperparameters](#16)\n",
    "     1. [Support Vector Machines (SVM)](#17)\n",
    "         1. [TODO No. 4: Implement SVM for classification and tune hyperparameters](#18)\n",
    "         1. [TODO No. 5: Implement SVM for regression](#19)\n",
    "   \n",
    "   https://scikit-learn.org/stable/model_selection.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "5ee3a7aa-eca4-411b-9f84-d14c09e13730",
    "_uuid": "2b90d6250c8f9c2c302c849bffa132bd3483e893"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Input data files are available in the \"./input/\" directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "32af03f6-41be-41ec-9023-8cd519040984",
    "_uuid": "a9c5426e9e5cef81c1e1639ebe57e9b45dfd2c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv('./input/column_2C_weka.csv')\n",
    "# print(plt.style.available) # look at available plot styles\n",
    "# plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('./input/column_2C_weka.csv')\n",
    "print(plt.style.available) # look at available plot styles\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "# plt.style.use('seaborn-darkgrid') line is having issues so i replaced it with sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65e897a1-8259-44c5-9cb7-e5e653f9032d",
    "_uuid": "a0e671bf2ef8dbe81da2705ad70b69401bb7af16"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## 1. Exploratory Data Analysis (EDA)\n",
    "* At the beginning, as you know, you need to explore and prepare data.\n",
    "* I always start with *head()* to see features, that are in our example *pelvic_incidence,\tpelvic_tilt numeric,\tlumbar_lordosis_angle,\tsacral_slope,\tpelvic_radius* and \t*degree_spondylolisthesis*, while target variable is *class*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c1ecd622-67cc-485f-bfa7-8c682d30a5eb",
    "_uuid": "9a5993f4962882e1156f2062b7abf706a0739d51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt numeric</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvic_incidence  pelvic_tilt numeric  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0         63.027817            22.552586              39.609117     40.475232   \n",
       "1         39.056951            10.060991              25.015378     28.995960   \n",
       "2         68.832021            22.218482              50.092194     46.613539   \n",
       "3         69.297008            24.652878              44.311238     44.644130   \n",
       "4         49.712859             9.652075              28.317406     40.060784   \n",
       "\n",
       "   pelvic_radius  degree_spondylolisthesis     class  \n",
       "0      98.672917                 -0.254400  Abnormal  \n",
       "1     114.405425                  4.564259  Abnormal  \n",
       "2     105.985135                 -3.530317  Abnormal  \n",
       "3     101.868495                 11.211523  Abnormal  \n",
       "4     108.168725                  7.918501  Abnormal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see features and target variable\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1631690c-bb9d-4460-a7d9-a335aa914b4f",
    "_uuid": "b7b9addc824de1a35b67d96d3092ffcb10869947"
   },
   "outputs": [],
   "source": [
    "# Check for NaN values and data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a7dd2a6f-a81d-4dce-9d74-fd0148c446ae",
    "_uuid": "96f97c33305956eb76d8a2043fd71aff05e38548"
   },
   "source": [
    "As you can see:\n",
    "* Length: 310 (range index)\n",
    "* Features are float\n",
    "* Target variable is object (string)\n",
    "* Now we have some ideas about data, but lets look go inside data deeper\n",
    "    * describe(): \n",
    "        * Why we need to see statistics like mean, std, max or min? \n",
    "        * Answer: In order to visualize data, values should be closer each other. As you can see values looks close. At least there are no incompatible values (e.g. mean of one feature is 0.1 and of other is 1000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "137897ca-b519-4ac3-afdd-6c4136447e39",
    "_uuid": "69d132068cce6a915aac7678b4e9fbcf3e365643"
   },
   "outputs": [],
   "source": [
    "# Check basic statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3776dd3d-d0aa-419e-b788-e75454e94b86",
    "_uuid": "c8961b1f3a3a73547a0b7d27955f9844f6ad43eb"
   },
   "source": [
    "Let's now visualise data.\n",
    "\n",
    "A **scatter plot matrix** is a grid (or matrix) of scatter plots used to visualize bivariate relationships between combinations of variables. Each scatter plot in the matrix visualizes the relationship between a pair of variables, allowing many relationships to be explored in one chart.\n",
    "A scatter plot is created for every pairwise combination of variables selected.\n",
    "\n",
    "pd.plotting.scatter_matrix:\n",
    "* green: *normal* and red: *abnormal*\n",
    "* c:  color\n",
    "* figsize: figure size\n",
    "* diagonal: histohram of each features\n",
    "* alpha: opacity\n",
    "* s: size of marker\n",
    "* marker: marker type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb106765-bb47-452b-8d6e-3578b479873c",
    "_uuid": "5dc0763dde8b2638a5289f0b4496f384f85aca85"
   },
   "outputs": [],
   "source": [
    "color_list = ['red' if i=='Abnormal' else 'green' for i in data.loc[:,'class']]\n",
    "pd.plotting.scatter_matrix(data.loc[:, data.columns != 'class'],\n",
    "                                       c=color_list,\n",
    "                                       figsize= [15,15],\n",
    "                                       diagonal='hist',\n",
    "                                       alpha=0.5,\n",
    "                                       s = 200,\n",
    "                                       marker = '*',\n",
    "                                       edgecolor= \"black\")\n",
    "plt.savefig('Scatter_matrix.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "53fc7ab6-de8b-4b8f-9e4a-38c5db72eea0",
    "_uuid": "d77cef37b8c5c4f07d3f4aa94cc4ad1ccbd7caca"
   },
   "source": [
    "Scatter matrix  presents the relations between each feature, but how many *normal(green)* and *abnormal(red)* classes are there? \n",
    "* Searborn library has *countplot()* that counts number of classes\n",
    "* Also you can print it with *value_counts()* method\n",
    "\n",
    "<br> This data looks balanced. Actually there is no definiton or numeric value of balanced data but this data is balanced enough for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "36243fa5-1fa6-4f8b-bc16-43449b0dc898",
    "_uuid": "e1bb9fd338e6900888e2e4717f54be46cee848a2"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=\"class\", data=data)\n",
    "plt.savefig('Value_counts.png')\n",
    "plt.show()\n",
    "data.loc[:,'class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "24a5d90f-3e7d-4733-a6f9-ff4f51145155",
    "_uuid": "9263c479815bb729dad40bf01b68aa18a3c946ac"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 2. CLASSIFICATION: K-Nearest Neighbors (KNN)\n",
    "\n",
    "<a id=\"3\"></a> <br>\n",
    "### 2.1 KNN\n",
    "\n",
    "<br> Now lets learn first **classification** method KNN.\n",
    "* KNN: Look at the K closest labeled data points\n",
    "* First we need to train our data (Train = *fit*)\n",
    "* fit(): fits the data, train the data.\n",
    "* predict(): predicts the data\n",
    "\n",
    "<br> Lets learn how to implement it with **sklearn**.\n",
    "* x: features\n",
    "* y: target variables (normal, abnormal)\n",
    "* n_neighbors: K. In this example it is 3, it means that algorithm looks at the 3 closest labeled data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c717491d-2bd5-4dc7-ac13-b9f581b1cddd",
    "_uuid": "854f0a3898a928640b9714fcd584e48c9b377f9f"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "x,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\n",
    "knn.fit(x,y)\n",
    "prediction = knn.predict(x)\n",
    "#print('Prediction: {}'.format(prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b5d85f4e-ab30-4c49-b2bc-6265b6baea9d",
    "_uuid": "6d9c3eacd279ddf7c0ef33b9e1814cd549d0feaa"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "### 2.2 Accuracy\n",
    "\n",
    "Well, we fit the data and predict it with KNN. \n",
    "Did we predict correct? What is our accuracy? \n",
    "\n",
    "<br> Measuring model performance:\n",
    "* **Accuracy**, which is the percentage of correct predictions, is commonly used metric. \n",
    "\n",
    "<br> As you noticed we trained our model with x (features) and again predict labels for x (features). Yes it is absurd :) But anyway, let's see the accuracy of our predictions in this case (do we expect 100%?).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of our model trained and tested with the same data\n",
    "print(knn.score(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "### 2.3 Split train and test data\n",
    "\n",
    "<br> In order for our tests to make sense we need to **split our data into train and test datasets**.\n",
    "* train: use train dataset for fitting\n",
    "* test: make prediction on test dataset\n",
    "* With train and test datasets, fitted data and tested data are completely different\n",
    "* train_test_split(x,y,test_size = 0.3,random_state = 1)\n",
    "    * x: features\n",
    "    * y: target variables (normal, abnormal)\n",
    "    * test_size: percentage of test size, e.g. test_size = 0.3, meaning test size = 30% and train size = 70%\n",
    "    * random_state: sets a seed; if this seed is the same number, train_test_split() produce the exact same split at each run\n",
    "* fit(x_train,y_train): fit on train datasets\n",
    "* score(x_test,y_test): predict and give accuracy on test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79865658-c89f-43c8-a1a9-75acc4feab6a",
    "_uuid": "4702429fdfa62650937b09fde5a8fd3136da8c55"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "x,y = data.loc[:,data.columns != 'class'], data.loc[:,'class']\n",
    "knn.fit(x_train,y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "#print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test)) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5665258-3f7f-435a-a634-49eb0c0d66e0",
    "_uuid": "544f51ef05efe0b3ae4b02da806778bcfa715f35"
   },
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "### 2.4 Model optimisation\n",
    "\n",
    "<br> Now the question is why we choose K = 3 or what value we need to choose for K. The answer is in model complexity\n",
    "\n",
    "<br> **Model complexity**:\n",
    "* K has a general name - it is called a **hyperparameter** and we need to choose it's value that gives the best performace. \n",
    "* Literature says if K is **too small**, than model is **complex model** can lead to **overfit**. It means that model memorizes the train sets too well and cannot predict on test set with good accuracy.\n",
    "* If K is **too big**, than model is **less complex** model can lead to **underfit**. \n",
    "* Below, we range K value from 1 to 25 (exclude) and find accuracy for each K value. As you can see in plot, when K is 1 it memorize train sets and cannot give good accuracy on test set (overfit). Also if K is more than 18, model is lead to underfit, with too low accuracy. However when K is 18 (best performance), accuracy has the highest value, of almost 88%. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "db2c7062-ce1b-4e8b-9b2f-0ee0cd679a91",
    "_uuid": "18d8739373085a9964071f38b8f2adcb64f25491"
   },
   "outputs": [],
   "source": [
    "# Model complexity\n",
    "k_range = np.arange(1, 25)\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(k_range):\n",
    "    # k from 1 to 25(exclude)\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # Fit with knn\n",
    "    knn.fit(x_train,y_train)\n",
    "    #train accuracy\n",
    "    train_accuracy.append(knn.score(x_train, y_train))\n",
    "    # test accuracy\n",
    "    test_accuracy.append(knn.score(x_test, y_test))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=[13,8])\n",
    "plt.plot(k_range, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(k_range, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.title('K-value vs. Accuracy')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(k_range)\n",
    "plt.savefig('K-value_vs_Accuracy.png')\n",
    "plt.show()\n",
    "print(\"Best accuracy is {} with K = {}\".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "### 2.5 Confusion matrix\n",
    "\n",
    "<br> Now lets discuss model performance. Is accuracy enough for measurement of model selection. For example, there is a data that includes 95% normal and 5% abnormal samples and our model uses accuracy for measurement metric. Then our model predict 100% normal for all samples and accuracy is 95% but it classifies all abnormal samples wrong. Therefore we need to use confusion matrix as a model measurement matrix in imbalance data.\n",
    "Confustion matrix:\n",
    "* tp = true positive(59), fp = false positive(7), fn = false negative(6), tn = true negative(21) \n",
    "* tp = Prediction is positive(normal) and actual is positive(normal). \n",
    "* fp = Prediction is positive(normal) and actual is negative(abnormal).\n",
    "* fn = Prediction is negative(abnormal) and actual is positive(normal).\n",
    "* tn = Prediction is negative(abnormal) and actual is negative(abnormal).\n",
    "* tpr = recall = tp/(tp+fn) = true positive rate or recall\n",
    "* tnr = tn/(tn+fp) = true negative rate\n",
    "* ba = (tpr+tnr)/2 = balanced accuracy\n",
    "* precision = tp / (tp+fp)\n",
    "* f1 = 2 * precision * recall / ( precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c71a33f5-5784-461b-949d-cb83f23dace6",
    "_uuid": "19fb6fb0f651e249835037a4f4b2f0b4a2619a27"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix with our example\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cm = confusion_matrix(y_test,prediction)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "print('Classification report: \\n',classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fcba81bb-1257-48d0-afe1-a4416237cc73",
    "_uuid": "f2697bbc248102687596713406512b4cb7f24929"
   },
   "outputs": [],
   "source": [
    "# visualize with seaborn library\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\") \n",
    "plt.savefig('Confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b598ee81-e535-49c0-b53c-b13b0a5058db",
    "_uuid": "96423b4f710966c8071647874623c139c1c79bb7"
   },
   "source": [
    "<a id=\"8\"></a> <br>\n",
    "## TODO No. 1: Random Forest (OPTIONAL)\n",
    "**<br> Lets try some other classification technique - Random Forest**\n",
    "* The idea and even most of the code (only KNeighborsClassifier need to be RandomForestClassifier) are the same. You need to split, fit, predict your data and measue performance and choose hyperparameter of random forest (like max_depth). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your input is expected here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f9d427a9-faa5-46cf-9e3c-2c8cea2571ad",
    "_uuid": "d075fd2a7c05e5414e33b7b1314d81a6b945e7b3"
   },
   "source": [
    "<a id=\"9\"></a> <br>\n",
    "## 3. REGRESSION\n",
    "* Supervised learning (labeled data is necessary)\n",
    "* The output (target) is the continuous value\n",
    "* This orthopedic patients data is not proper for regression so we will only use two features that seems highly correlated based on our scatter plot matrix: *sacral_slope* and *pelvic_incidence* of abnormal data class\n",
    "    * Lets consider that feature (input) is *pelvic_incidence* and target (output) is *sacral_slope* \n",
    "    * Lets look at magnified scatter plot so to understand it better\n",
    "    * reshape(-1,1): If you do not use it x or y become 1D arrays with the shape (210,) and we cannot use it in sklearn, so we use reshape(-1,1) and x or y become 2D arrays with the shape (210, 1). In detail we reshape it to unknown number of raws (-1) and to 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b072c42-059f-4e45-9cfa-8ed39b274f72",
    "_uuid": "d2655c140423b1228c42d2e8dfe54344ba43dcb0"
   },
   "outputs": [],
   "source": [
    "# Create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable\n",
    "data1 = data[data['class'] =='Abnormal']\n",
    "\n",
    "# Uncomment below if you want to see what reshape(-1,1) is about \n",
    "#xt = np.array(data1.loc[:,'pelvic_incidence'])\n",
    "#print(xt.shape)\n",
    "#print(xt)\n",
    "#x = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\n",
    "#print(x.shape)\n",
    "#print(x)\n",
    "\n",
    "x = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\n",
    "y = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\n",
    "# Scatter\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.scatter(x=x,y=y)\n",
    "plt.xlabel('pelvic_incidence')\n",
    "plt.ylabel('sacral_slope')\n",
    "plt.savefig('Scatter_plot_reg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "874ac5e0-5bc0-4429-b6c5-707690b5dd77",
    "_uuid": "c84719d363ff736e96a0a575dfd0381bcbc549fb"
   },
   "source": [
    "<a id=\"10\"></a> <br>\n",
    "### 3.1 Linear Regression\n",
    "Now we have our data to make regression. In regression problems target value is continuously varying variable such as price of house or *sacral_slope*. Lets fit line into this points.\n",
    "\n",
    "<br> Linear regression\n",
    "* y = ax + b       where  y = target, x = feature and a = parameter of model\n",
    "* We choose parameter of model (a) according to minimum error function - lost function\n",
    "* In linear regression we will use Ordinary Least Square (OLS) as lost function.\n",
    "* OLS: Sum all residuals but because some positive and negative residuals can cancel each other, we sum the square of residuals. \n",
    "* Score: Score uses R^2 method that is ((y_pred - y_mean)^2 )/(y_actual - y_mean)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fb7991f3-5869-4df0-bf6c-30f61e8215c6",
    "_uuid": "7cdc74efa8c46dab5f14f6cc2779928c11a4fa62"
   },
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "# Predict space\n",
    "predict_space = np.linspace(min(x), max(x)).reshape(-1,1)\n",
    "# Fit\n",
    "reg.fit(x,y)\n",
    "# Predict\n",
    "predicted = reg.predict(predict_space)\n",
    "# R^2 \n",
    "print('R^2 score: ',reg.score(x, y))\n",
    "# Plot regression line and scatter\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.plot(predict_space, predicted, color='black', linewidth=3)\n",
    "plt.scatter(x=x,y=y)\n",
    "plt.xlabel('pelvic_incidence')\n",
    "plt.ylabel('sacral_slope')\n",
    "plt.savefig('Scatter_matrix_reg_lin.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "27ffec30-4951-4479-9d86-32495a80c08d",
    "_uuid": "be425f142c0acc1ab3009fafafa3616948f5c8a5"
   },
   "source": [
    "<a id=\"11\"></a> <br>\n",
    "### 3.2 Regularized Regression\n",
    "As we learned so far linear regression choose parameters (coefficients) while minimizing lost function. If linear regression considers that one of the features is important, it gives high coefficient to this feature. However, this can cause overfitting (similar to memorizing in KNN). In order to avoid overfitting, we can use regularization that penalize large coefficients.\n",
    "\n",
    "* **Ridge regression**: First regularization technique. Also it is called L2 regularization. \n",
    "    * Ridge regression lost fuction = OLS + alpha * sum(parameter^2)\n",
    "    * Alpha is parameter we need to choose to fit and predict. Picking alpha is similar to picking K in KNN. So alpha is hyperparameter that we need to choose for best accuracy and model complexity. This process is called hyperparameter tuning.\n",
    "    * What if alpha is zero? Lost function = OLS so it is linear rigression.\n",
    "    * If alpha is too small that can cause overfitting.\n",
    "    * If alpha is too big that can cause underfitting. \n",
    "* **Lasso regression**: Second regularization technique. Also it is called L1 regularization. \n",
    "    * Lasso regression lost fuction = OLS + alpha * sum(absolute_value(parameter))\n",
    "    * It can be used to select important features of the data. \n",
    "    * In order to demonstrate choosing features, we will add new features in our regression data.\n",
    "    \n",
    "<br> Linear vs Ridge vs Lasso\n",
    "* First impression: Linear\n",
    "* Feature Selection: 1.Lasso 2.Ridge\n",
    "* Regression model: 1.Ridge 2.Lasso 3.Linear \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bdc1a379-07a4-4b61-8ac1-d7007ae33783",
    "_uuid": "85fa872e3988295a8fbe752bf96319518ca3595b"
   },
   "outputs": [],
   "source": [
    "# Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 2, test_size = 0.3)\n",
    "ridge = Ridge(alpha = 0.1, normalize = True)\n",
    "ridge.fit(x_train,y_train)\n",
    "ridge_predict = ridge.predict(x_test)\n",
    "print('Ridge score: ',ridge.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de031d9f-b2f8-4fb1-a305-36cbc4dc970f",
    "_uuid": "57f91f4b4e267bd3eb22adfcdf719778c1901c92"
   },
   "outputs": [],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "x = np.array(data1.loc[:,['pelvic_incidence','pelvic_tilt numeric','lumbar_lordosis_angle','pelvic_radius']])\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 3, test_size = 0.3)\n",
    "lasso = Lasso(alpha = 0.1, normalize = True)\n",
    "lasso.fit(x_train,y_train)\n",
    "ridge_predict = lasso.predict(x_test)\n",
    "print('Lasso score: ',lasso.score(x_test,y_test))\n",
    "print('Lasso coefficients: ',lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84f9d88d-28e9-4b26-8824-ae32de7e143c",
    "_uuid": "d70e2366ccc8797c92d2edacb4ab3b59fad4506d"
   },
   "source": [
    "As you can see *pelvic_incidence* and *pelvic_tilt numeric* are important features but other two are not important!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> <br>\n",
    "## TODO No. 2: Regression (OPTIONAL)\n",
    "**<br> Lets plot these regression methods**\n",
    "* Plot scatter plots and lines on test dataset for Linear, Ridge and Lasso regression methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your input is expected here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4552b965-e15d-4e05-9e02-224159e8d508",
    "_uuid": "dbe175099c0c8151c16ad0c78f1414de8fd9ebdc"
   },
   "source": [
    "<a id=\"13\"></a> <br>\n",
    "## 4 Logistic Regression and ROC Curve\n",
    "**Logistic regression**\n",
    "* Logistic regression has probabilities as the output\n",
    "* If probability is higher than 0.5 data is labeled 1 (abnormal) else 0 (normal)\n",
    "* By default logistic regression threshold is 0.5\n",
    "\n",
    "**ROC curve**\n",
    "* ROC is receiver operationg characteristic. In this curve x axis is false positive rate and y axis is true positive rate\n",
    "* Different points on ROC correspond to different threshold values\n",
    "* If the curve in plot is closer to left-top corner, test is more accurate.\n",
    "* ROC curve score is AUC that is computation area under the curve from prediction scores\n",
    "* We want AUC to be closer to 1\n",
    "* fpr = False Positive Rate\n",
    "* tpr = True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f4a8f76-9792-485f-83b0-79e2524ab83c",
    "_uuid": "c7fce3a219764388088ec5f3d57ab913f5c05f35"
   },
   "outputs": [],
   "source": [
    "# ROC Curve with logistic regression\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# abnormal = 1 and normal = 0\n",
    "data['class_binary'] = [1 if i == 'Abnormal' else 0 for i in data.loc[:,'class']]\n",
    "x,y = data.loc[:,(data.columns != 'class') & (data.columns != 'class_binary')], data.loc[:,'class_binary']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred_prob = logreg.predict_proba(x_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# Plot ROC curve\n",
    "plt.clf()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.savefig('ROC.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a> <br>\n",
    "## 5. Cross validation\n",
    "In KNN method we used train test split with random_state that split the dataset in exactly the same way each time. However, if we do not use random_state, data is split differently at each time and accuracy will be different. Therefore, we can conclude that model performance is dependent on the train_test_split. For example you split, fit and predict data 5 times and accuracies are 0.89, 0.9, 0.91, 0.92 and 0.93, respectively. Which accuracy do you use? Do you know what accuracy will be at 6th times split, train and predict? There is not certain answer but if you use cross validation you can find acceptable accuracy.\n",
    "<br> Cross Validation (CV)\n",
    "* K folds = K fold CV.\n",
    "* When K is increased, computational cost is increased\n",
    "* cross_val_score(reg,x,y,cv=5): it means 5 times (split, train, predict) for linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (From the last time) Create data1 that includes pelvic_incidence that is feature and sacral_slope that is target variable\n",
    "data1 = data[data['class'] =='Abnormal']\n",
    "x = np.array(data1.loc[:,'pelvic_incidence']).reshape(-1,1)\n",
    "y = np.array(data1.loc[:,'sacral_slope']).reshape(-1,1)\n",
    "# Scatter\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.scatter(x=x,y=y)\n",
    "plt.xlabel('pelvic_incidence')\n",
    "plt.ylabel('sacral_slope')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation (CV)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "k = 5\n",
    "cv_result = cross_val_score(reg,x,y,cv=k) # uses R^2 as score \n",
    "print('CV Scores: ',cv_result)\n",
    "print('CV scores average: ',np.sum(cv_result)/k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"15\"></a> <br>\n",
    "## 6. Hyperparameter tunning\n",
    "As we mentioned the last time there are hyperparameters that are need to be tuned\n",
    "* For example: \n",
    "    * k at KNN\n",
    "    * alpha at linear regression, Ridge and Lasso\n",
    "    * max_depth at Random forest\n",
    "* Hyperparameter tuning: \n",
    "    * try all combinations for different parameters\n",
    "    * fit all of them\n",
    "    * measure prediction performance\n",
    "    * see how well each performs\n",
    "    * finally choose best hyperparameters\n",
    "* We only need one line code for this: GridSearchCV\n",
    "    * grid: K is from 1 to 50 (exclude)\n",
    "    * GridSearchCV takes knn and grid and makes grid search. It means combination of all hyperparameters. For KNN it is k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class_binary'] = [1 if i == 'Abnormal' else 0 for i in data.loc[:,'class']]\n",
    "x,y = data.loc[:,(data.columns != 'class') & (data.columns != 'class_binary')], data.loc[:,'class_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation with 1 hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "grid = {'n_neighbors': np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=3) # GridSearchCV\n",
    "knn_cv.fit(x,y)# Fit\n",
    "\n",
    "# Print hyperparameter\n",
    "print(\"Tuned hyperparameter k: {}\".format(knn_cv.best_params_)) \n",
    "print(\"Best score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cross validation with 1 hyperparameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3,random_state = 1)\n",
    "\n",
    "grid = {'n_neighbors': np.arange(1,50)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=3) # GridSearchCV\n",
    "knn_cv.fit(x_train,y_train)# Fit\n",
    "\n",
    "# Print hyperparameter\n",
    "print(\"Tuned hyperparameter k: {}\".format(knn_cv.best_params_)) \n",
    "print(\"Best score: {}\".format(knn_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = knn_cv.predict(x_test)\n",
    "print(knn_cv.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"16\"></a> <br>\n",
    "### TODO No.3:  Grid search example with 2 hyperparameters\n",
    "* First hyperparameter is *C*: logistic regression regularization parameter\n",
    "    * If C is high: overfit\n",
    "    * If C is low: underfit\n",
    "* Second hyperparameter is *penalty* (loss function): l1 (Lasso) or l2 (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO No.3!!! \n",
    "\n",
    "# Grid search cross validation with 2 hyperparameter for Logistic Regression\n",
    "# 1. hyperparameter is C: logistic regression regularization parameter\n",
    "# 2. penalty l1 or l2\n",
    "# Use hyperparameter grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> <br>\n",
    "## 7. Support Vector Machines\n",
    "\n",
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "The advantages of support vector machines are:\n",
    "\n",
    "* Effective in high dimensional spaces.\n",
    "\n",
    "* Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "\n",
    "* Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "\n",
    "* Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
    "\n",
    "The disadvantages of support vector machines include:\n",
    "\n",
    "* If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "\n",
    "* SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a>\n",
    "### 7.1 SVM for classification\n",
    "SVC, NuSVC and LinearSVC are scikit-learn classes capable of performing binary and multi-class classification on a dataset.\n",
    "\n",
    "SVC and NuSVC are similar methods, accept slightly different sets of parameters and different mathematical formulations. On the other hand, LinearSVC is another (faster) implementation of Support Vector Classification for the case of a linear kernel. \n",
    "\n",
    "As other classifiers, SVC, NuSVC and LinearSVC take as input two arrays: an array X of shape (n_samples, n_features) holding the training samples, and an array y of class labels (strings or integers), of shape (n_samples).\n",
    "\n",
    "NOTE: Support Vector Machine algorithms are not scale invariant, so it is highly recommended to **scale** your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1. Note that the same scaling must be applied to the test vector to obtain meaningful results. This can be done easily by using a **Pipeline**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"18\"></a> <br>\n",
    "### TODO No. 4: Implement SVM for classification and tune hyperparameters\n",
    "\n",
    "* Apply SVM for classification\n",
    "* Scale your data\n",
    "* Use Pipeline method\n",
    "* Tune two hyperparameters:\n",
    "    * 'SVM__C' e.g. (1,100)\n",
    "    * 'SVM__gamma' e.g. (0.1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class_binary'] = [1 if i == 'Abnormal' else 0 for i in data.loc[:,'class']]\n",
    "x,y = data.loc[:,(data.columns != 'class') & (data.columns != 'class_binary')], data.loc[:,'class_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, to find the names and current values for all parameters for a given estimator, use:\n",
    "# estimator.get_params()\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO No.4!!!\n",
    "\n",
    "# Apply SVC, scale, pipeline and tune 'SVM__C' and 'SVM__gamma' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> <br>\n",
    "### 7.2 SVM for regression\n",
    "\n",
    "The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.\n",
    "\n",
    "There are three different implementations of Support Vector Regression in scikit-learn: SVR, NuSVR and LinearSVR. LinearSVR provides a faster implementation than SVR but only considers the linear kernel, while NuSVR implements a slightly different formulation than SVR and LinearSVR. \n",
    "\n",
    "As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"19\"></a> <br>\n",
    "### TODO No. 5: Implement SVM for regression\n",
    "\n",
    "* Apply SVM for regression\n",
    "* Scale your data\n",
    "* Use Pipeline method\n",
    "\n",
    "* Tune three hyperparameters:\n",
    "    * kernel e.g. {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’} \n",
    "    * 'SVM__C' e.g. (1,100)\n",
    "    * 'SVM__gamma' e.g. (0.1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "SVR().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO No.5!!!\n",
    "\n",
    "# Apply SVR, scale, pipeline and tune 'SVM__kernel' 'SVM__C' and 'SVM__gamma' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "41762172-8d1f-47ef-b8ab-79fb3a2b0a19",
    "_uuid": "2c1a42c1de45ce53e04761b4b6c05840fddaee95"
   },
   "source": [
    "## Attributions and License:\n",
    "\n",
    "Notebook based on [https://www.kaggle.com/code/kanncaa1/machine-learning-tutorial-for-beginners/notebook].\n",
    "\n",
    "This work is licensed under the [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0) open source license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
